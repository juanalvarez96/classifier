{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier and preprocessing\n",
    "\n",
    "In this notebook, the noironicos dataset will be treated, since ironicos's tweets are all ironic and we want a mixture of ironic and non ironic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ironic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Algunas personas sufren en las discos mientras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@jacevedoaraya es para sostener el marcador......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Alguna de estas imágenes te sacara una sonrisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>@_Eurovision2014 en 2013 falta esdm jajajajaja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Hooo que buen padre...#Sarcasmo #GH2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ironic                                               text\n",
       "0      1  Algunas personas sufren en las discos mientras...\n",
       "3      1  @jacevedoaraya es para sostener el marcador......\n",
       "4      1  Alguna de estas imágenes te sacara una sonrisa...\n",
       "5      1  @_Eurovision2014 en 2013 falta esdm jajajajaja...\n",
       "6      1            Hooo que buen padre...#Sarcasmo #GH2015"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General import and load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "# Import database\n",
    "df_noironicos=pd.read_csv('noironicos_bodies.csv')\n",
    "\n",
    "# Encode categorical variable (ironic)\n",
    "df_noironicos.loc[df_noironicos['ironic']==True, \"ironic\"] = 1\n",
    "df_noironicos.loc[df_noironicos['ironic']==False, \"ironic\"] = 0\n",
    "\n",
    "# Drop non-used columns\n",
    "df_noironicos.drop(['id_tweet', 'depends_image', 'depends_link', 'depends_retweet'], axis=1, inplace=True)\n",
    "\n",
    "# Drop nan rows\n",
    "df_clean=df_noironicos.dropna(subset=['text'])\n",
    "df_noironicos=df_clean\n",
    "\n",
    "# Final dataset\n",
    "df_noironicos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\n",
    "X = df_noironicos['text'].values\n",
    "y = df_noironicos['ironic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical features\n",
    "The lexical features analysis will be performed by using the twitter tokenizer provided by nltk library.\n",
    "\n",
    "PUEDE QUE HAYA UN PROBLEMA EN LA PARTE DE LOS EMOTICONOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Insert all words of the tweets in a list\n",
    "tokens_ar = []\n",
    "lemmas_ar = []\n",
    "# Used later for cleansing\n",
    "ht = re.compile(r'http.')\n",
    "bar = re.compile(r'//*')\n",
    "pr = [\"rt\",\"@\",\"http\",\"https\",\"'s\",'...', 'english', 'translation','):', '. .', '..']\n",
    "X_str = X.astype('str')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "stoplist = stopwords.words('spanish')\n",
    "punctuation = set(string.punctuation)\n",
    "for tweet in X_str:\n",
    "    tokens=tknzr.tokenize(tweet)\n",
    "    tokens_ar.append(tokens)\n",
    "porter = PorterStemmer()\n",
    "for tokens in tokens_ar:\n",
    "    # Get lemmas\n",
    "    lemmas = [porter.stem(t) for t in tokens]\n",
    "    # Remove unnecessary words\n",
    "    lemmas_clean = [w for w in lemmas if w not in stoplist]\n",
    "    # Remove punctuation\n",
    "    lemmas_punct = [w for w in lemmas_clean if  w not in punctuation]\n",
    "    # Clean emojis, urls, bars, etc (ATENCIÓN:CREO QUE NO FUNCIONA)\n",
    "    lemmas_clean = [w for w in lemmas_punct if not w.startswith('@') if w not in pr \n",
    "            if not bar.search(w) if not ht.search(w)\n",
    "            if not w.isdigit()]\n",
    "    lemmas_ar.append(lemmas_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
